 <!-- # <p align=center>`awesome gan-inversion`</p> -->
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](https://github.com/lxtGH/Awesome-Segmenation-With-Transformer/pulls)
![](https://img.shields.io/badge/Status-building-red)
<br />

<p align="center">
  <h1 align="center">A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation</h1>
  <p align="center">
    arXiv, 2023
    <br />
    <a href="/"><strong>Li Liu</strong></a>
    ·
    <a href="/"><strong>Lufei Gao</strong></a>
    ·
    <a href="/"><strong>Wentao Lei</strong></a>
    ·
    <a href="/"><strong>Fengji Ma</strong></a>
    ·
    <a href="/"><strong>Xiaotian Lin</strong></a>
    <br />
    <a href="/"><strong>Jinting Wang</strong></a>
  </p>

  <p align="center">
    <a href='link'>
      <img src='https://img.shields.io/badge/Paper-PDF-green?style=flat&logo=arXiv&logoColor=green' alt='arXiv PDF'>
    </a>
    <a href='link' style='padding-left: 0.5rem;'>
      <img src='https://img.shields.io/badge/Project-Page-blue?style=flat&logo=Google%20chrome&logoColor=blue' alt='S-Lab Project Page'>
    </a>
  </p>
<br />

This repo is used for recording and tracking some Multi-modal Body Language researchs,
as a supplement to our [survey](link).  
If you find any work missing or have any suggestions (papers, implementations and other resources), please don't hesitate to open an issue or pull request.
We will add the missing papers to this repo ASAP.


### 🔥News
[-2023.8.19] The second draft is on arxiv. 

[-2023.8.7 ] The first draft is on arxiv. 

### 🔥Highlight!!

[1] We re-visit and group the existing Body Language researchs from the **Multi-modal perspective.**

[2] We survey the research in 4 parts: Cued Speech, Co-speech, Sign Language, Talking Head.

[3] We survey the research in 2 directions: Recognition and Generation.

[4] Some new insight for this directions are discussed.


## Introduction

In this survey, we present the first detailed survey on Multi-modal Body Language research.

![Alt Text](Outline-paper.png)

## Summary of Contents

- [Paper List](#Paper-List)
  - [Recognition](#Recognition)
    - [Cued Speech Recognition](#Cued-Speech-Recognition)
    - [Co-speech Recognition](#Co-speech-Recognition)
    - [Sign Language Recognition](#Sign-Language-Recognition)
    - [Talking Head Recognition](#Talking-Head-Recognition)
  - [Generation](#Generation)
    - [Cued Speech Generation](#Cued-Speech-Generation)
    - [Co-speech Generation](#Co-speech-Generation)
    - [Sign Language Generation](#Co-Language-Generation)
    - [Talking Head Generation](#Talking-Head-Generation)

[//]: # (  )

## Paper-List

### Cued Speech Recognition
| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2020 |  CVPR   |      DETR       | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)                                     | [Code](https://github.com/facebookresearch/detr)             |
|      |         |                 |                                                                                                                       |  N/A                                                         |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |


#### Co-speech Recognition

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2020 |  CVPR   |      DETR       | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)                                     | [Code](https://github.com/facebookresearch/detr)             |
|      |         |                 |                                                                                                                       |  N/A                                                         |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
#### Sign Language Recognition

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2019 |  CVPR   |  Zhang et al.   | [Continuous Sign Language Recognition via Reinforcement Learning](https://ieeexplore.ieee.org/document/8802972)                                     | N/A             |
| 2020 |  ECAI   |  Zhou et al. | [Self-Attention-based Fully-Inception Networks for Continuous Sign Language Recognition](https://ieeexplore.ieee.org/document/8802972) |  N/A   |
| 2020 | ICASSP |   Li et al. | [Key Action and Joint CTC-Attention based Sign Language Recognition](https://ieeexplore.ieee.org/abstract/document/9054316) |  N/A  |
| 2020 | ECCV  | Cheng et al. | [Fully Convolutional Networks for Continuous Sign Language Recognition](https://link.springer.com/chapter/10.1007/978-3-030-58586-0_41)  | N/A |
| 2020 | ECCV | Niu et al. | [Stochastic Fine-Grained Labeling of Multi-state Sign Glosses for Continuous Sign Language Recognition](https://link.springer.com/chapter/10.1007/978-3-030-58517-4_11)  | N/A |
| 2021 | ICPR | Koishybay et al. | [Continuous Sign Language Recognition with Iterative Spatiotemporal Fine-tuning](https://ieeexplore.ieee.org/abstract/document/9412364) | N/A|
| 2022 | CVPR | Zuo et al. | [C2SLR: Consistency-Enhanced Continuous Sign Language Recognition](https://openaccess.thecvf.com/content/CVPR2022/html/Zuo_C2SLR_Consistency-Enhanced_Continuous_Sign_Language_Recognition_CVPR_2022_paper.html) | N/A |
| 2022 | IEEE Transactions on Multimedia | Zhou et al. | [Spatial-Temporal Multi-Cue Network for Sign Language Recognition and Translation](https://ieeexplore.ieee.org/abstract/document/9354538) | N/A |


#### Talking Head Recognition

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2020 |  CVPR   |      DETR       | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)                                     | [Code](https://github.com/facebookresearch/detr)             |
|      |         |                 |                                                                                                                       |  N/A                                                         |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |

#### Cued Speech Generation

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
|  1998  |  ISCA  | Paul et al.     |    [Automatic Generation of Cued Speech for The Deaf: Status and Outlook](https://isca-speech.org/archive_open/archive_papers/avsp98/av98_161.pdf)                                                                                       |  N/A                                                         |
|  2008 |   AVSP   |  G ́erard et al.     |    [Retargeting cued speech hand gestures for different talking heads and speakers](https://www.isca-speech.org/archive/avsp_2008/bailly08b_avsp.html)                                                                      |                  N/A                                     |
#### Co Speech Generation

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2015 | IVA |      DCNF       | [Predicting co-verbal gestures: A deep and temporal modeling approach](https://www.stacymarsella.org/publications/pdf/ChiuIVA15.pdf)                                     | N/A            |
| 2019 | CVPR  |        S2G         |      [Learning individual styles of conversational gesture](https://openaccess.thecvf.com/content_CVPR_2019/papers/Ginosar_Learning_Individual_Styles_of_Conversational_Gesture_CVPR_2019_paper.pdf)                                                                                                                 |  [code](https://github.com/amirbar/speech2gesture)                                                         | 
|  2020  | EUROGRAPHICS |        StyleGestures         |      [Style-Controllable Speech-Driven Gesture Synthesis Using Normalising Flows](https://www.diva-portal.org/smash/get/diva2:1499133/FULLTEXT01.pdf)                                                                                                |      [code](https://github.com/simonalexanderson/StyleGestures/)                                                        |
|  2021    | ICCV |        A2G         |            [Audio2Gestures: Generating Diverse Gestures from Speech Audio with
Conditional Variational Autoencoders](https://arxiv.org/abs/2301.06690)                                                                                                           |                                                              | [code](https://jingli513.github.io/audio2gestures/)
|  2021  |  IEEE VR  |          Text2Gestures       |           [Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents](https://arxiv.org/abs/2101.11101)                                                                                                            |     [code](https://github.com/UttaranB127/Text2Gestures)                                                     
|  2022  | Computer Graphics Forum |        ZeroEGGS             |   [ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech](https://onlinelibrary.wiley.com/doi/10.1111/cgf.14734)      |   [code](https://github.com/ubisoft/ubisoft-laforge-ZeroEGGS)
|  2022  |   CVPR    |         DiffGAN             |        [Low-Resource Adaptation for Personalized Co-Speech Gesture Generation](https://openaccess.thecvf.com/content/CVPR2022/papers/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf)                    |    N/A
|  2022  |   SIGGRAPH Asia    |          RG            |       [Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings](https://arxiv.org/abs/2210.01448)                |  [code](https://github.com/Aubrey-ao/HumanBehaviorAnimation)

#### Sign Language Generation

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2016 |  Universal Access in the Information Society   |      Sign3D     | [Interactive editing in French Sign Language dedicated to virtual signers: requirements and challenges](https://link.springer.com/article/10.1007/s10209-015-0411-6)                                     | N/A|
| 2018 |  AAAI   |      DETR       | [Hierarchical LSTM for Sign Language Translation](https://arxiv.org/abs/2005.12872)                                    | N/A              |
|  2020          |    IJCV         |    text2gesture             | [Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks](https://link.springer.com/article/10.1007/s11263-019-01281-2)                                                                                                 |  N/A           |
|  2020  |         |    ESN       |                                                                                                                       |                     |
| 2020     |         |    Saunders et al.|                                                                                                                       |         |
| 2022  |         |     DSM        |                                                                                                                       |                     |
|  2022  |  CVPR   |      SignGAN    |    [Signing at Scale: Learning to Co-Articulate Signs for Large-Scale Photo-Realistic Sign Language Production](https://arxiv.org/abs/2203.15354)          |       N/A                                           |
| 2023  |   CVPR   |    PoseVQ-Diffusion     |  [Vector Quantized Diffusion Model with CodeUnet for Text-to-Sign Pose Sequences Generation](https://arxiv.org/abs/2208.09141)                                                                                  |    [Code](https://github.com/cientgu/VQ-Diffusion)                                                          |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |

#### Talking Head Generation

| Year |  Venue  |     Acronym     | Paper Title                                                                                                           | Code/Project                                                 |
|:----:|:-------:|:---------------:|-----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| 2020 |  CVPR   |      DETR       | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)                                     | [Code](https://github.com/facebookresearch/detr)             |
|      |         |                 |                                                                                                                       |  N/A                                                         |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |
|      |         |                 |                                                                                                                       |                                                              |

## Acknowledgement

If you find our survey and repository useful for your research project, please consider citing our paper:

```bibtex
@article{liu2023blsurvey,
  title={A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation},
  author={Liu, Li and Lufei, Gao  and Wentao, Lei and Fengji, Ma and Xiaotian, Lin and Jinting, Wang },
  journal={arXiv:xxxx},
  year={2023}
}
```
## Contact
```
avrillliu@hkust-gz.edu.cn
```
```
wentaolei@hkust-gz.edu.cn
```
## Related Repo of Our Group

Awesome-Segment-Anything [Repo](https://github.com/liliu-avril/Awesome-Segment-Anything) by Chunhui Zhang.

